{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7pOkf9efhLmF"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(r'data\\fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv(r'data\\fashion-mnist_test.csv')\n",
        "\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "NEnOZVXJhX06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the training and testing data into X (image) and Y (label) arrays\n",
        "\n",
        "train_data = np.array(train_df, dtype='float32')\n",
        "test_data = np.array(test_df, dtype='float32')\n",
        "\n",
        "x_train = train_data[:, 1:] / 255\n",
        "y_train = train_data[:, 0]\n",
        "\n",
        "x_test = test_data[:, 1:] / 255\n",
        "y_test = test_data[:, 0]"
      ],
      "metadata": {
        "id": "tLlcYGynokHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the training data into train and validate arrays (will be used later)\n",
        "\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(\n",
        "    x_train, y_train, test_size=0.2, random_state=12345,\n",
        ")"
      ],
      "metadata": {
        "id": "ms6f5Ef7okYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see what the images look like\n",
        "\n",
        "image = x_train[50, :].reshape((28, 28))\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hSm1TbLiokmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_rows = 28\n",
        "im_cols = 28\n",
        "batch_size = 512\n",
        "im_shape = (im_rows, im_cols, 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], *im_shape)\n",
        "\n",
        "print('x_train shape: {}'.format(x_train.shape))\n",
        "print('x_test shape: {}'.format(x_test.shape))\n",
        "print('x_validate shape: {}'.format(x_validate.shape))"
      ],
      "metadata": {
        "id": "CA3svHqWok1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "gon3nPyupIVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard = TensorBoard(\n",
        "    log_dir=r'logs\\{}'.format('cnn_1layer'),\n",
        "    write_graph=True,\n",
        "    write_grads=True,\n",
        "    histogram_freq=1,\n",
        "    write_images=True,\n",
        ")\n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "0WibWHAIpIh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(\n",
        "    x_train, y_train, batch_size=batch_size,\n",
        "    epochs=10, verbose=1,\n",
        "    validation_data=(x_validate, y_validate),\n",
        "    callbacks=[tensorboard]\n",
        ")"
      ],
      "metadata": {
        "id": "NCG4lPyBpIvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('test loss: {:.4f}'.format(score[0]))\n",
        "print(' test acc: {:.4f}'.format(score[1]))"
      ],
      "metadata": {
        "id": "SAvPMdK0pP9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}